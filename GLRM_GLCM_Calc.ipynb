{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#GPU_GLCM_Calc:-"
      ],
      "metadata": {
        "id": "K8j0NGCcW7xQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1g5CdS0WvDe"
      },
      "outputs": [],
      "source": [
        "# Install CuPy for GPU accelerated operations (adjust the version if needed).\n",
        "# !pip install cupy-cuda11x\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# # Mount Google Drive to access your dataset\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Define the base path where the labeled folders are stored on Google Drive.\n",
        "# # Adjust the base path accordingly.\n",
        "# base_path = '/content/drive/MyDrive/path_to_images'\n",
        "base_path = final_path\n",
        "\n",
        "# List of folder names (labels)\n",
        "labels = ['battery', 'biological', 'brown-glass', 'cardboard', 'clothes',\n",
        "          'green-glass', 'metal', 'paper', 'plastic', 'shoes', 'trash', 'white-glass']\n",
        "\n",
        "# Collect all image file paths with their associated labels.\n",
        "image_files = []\n",
        "for label in labels:\n",
        "    folder_path = os.path.join(base_path, label, '*.jpg')\n",
        "    files = glob.glob(folder_path)\n",
        "    # Save a tuple of (file_path, label) for each image.\n",
        "    for f in files:\n",
        "        image_files.append((f, label))\n",
        "\n",
        "print(f\"Found {len(image_files)} images across {len(labels)} labels.\")\n",
        "\n",
        "def quantize_image(image, levels=8):\n",
        "    \"\"\"\n",
        "    Quantize a grayscale image to a fixed number of intensity levels.\n",
        "    \"\"\"\n",
        "    factor = 256 // levels\n",
        "    return (image // factor).astype(np.uint8)\n",
        "\n",
        "def compute_glcm_features_for_offset(gray, levels=8, offset=(0,1)):\n",
        "    \"\"\"\n",
        "    Compute the GLCM (for a given offset) and extract features using GPU.\n",
        "\n",
        "    Parameters:\n",
        "      gray   : 2D numpy array (quantized grayscale image)\n",
        "      levels : Number of gray levels (default is 8)\n",
        "      offset : Tuple (dy, dx) defining the spatial relationship.\n",
        "               For example, (0,1) corresponds to a horizontal neighbor.\n",
        "\n",
        "    Returns:\n",
        "      Dictionary with computed GLCM features.\n",
        "    \"\"\"\n",
        "    # Convert image to a CuPy array\n",
        "    gpu_img = cp.asarray(gray)\n",
        "    rows, cols = gpu_img.shape\n",
        "    dy, dx = offset\n",
        "\n",
        "    # Determine valid slice indices for the image and its neighbor based on the offset.\n",
        "    if dy >= 0:\n",
        "        row_range = slice(0, rows - dy)\n",
        "        row_range_offset = slice(dy, rows)\n",
        "    else:\n",
        "        row_range = slice(-dy, rows)\n",
        "        row_range_offset = slice(0, rows + dy)\n",
        "\n",
        "    if dx >= 0:\n",
        "        col_range = slice(0, cols - dx)\n",
        "        col_range_offset = slice(dx, cols)\n",
        "    else:\n",
        "        col_range = slice(-dx, cols)\n",
        "        col_range_offset = slice(0, cols + dx)\n",
        "\n",
        "    # Extract corresponding pixel pairs for the given offset.\n",
        "    a = gpu_img[row_range, col_range]\n",
        "    b = gpu_img[row_range_offset, col_range_offset]\n",
        "\n",
        "    # Flatten the arrays and compute a combined index for the co-occurrence.\n",
        "    a_flat = a.ravel()\n",
        "    b_flat = b.ravel()\n",
        "    indices = a_flat * levels + b_flat\n",
        "\n",
        "    # Count occurrences using GPU-accelerated bincount.\n",
        "    glcm_counts = cp.bincount(indices, minlength=levels*levels).reshape(levels, levels)\n",
        "\n",
        "    # Normalize the GLCM to create a probability matrix.\n",
        "    glcm_prob = glcm_counts.astype(cp.float32)\n",
        "    total = cp.sum(glcm_prob)\n",
        "    if total > 0:\n",
        "        glcm_prob /= total\n",
        "\n",
        "    # Create index grids for feature computations.\n",
        "    i = cp.arange(levels).reshape(-1, 1)\n",
        "    j = cp.arange(levels).reshape(1, -1)\n",
        "\n",
        "    # Calculate features:\n",
        "    contrast = cp.sum((i - j)**2 * glcm_prob)\n",
        "    energy = cp.sum(glcm_prob**2)\n",
        "    homogeneity = cp.sum(glcm_prob / (1 + cp.abs(i - j)))\n",
        "\n",
        "    # For correlation, compute marginal means and standard deviations.\n",
        "    pi = cp.sum(glcm_prob, axis=1, keepdims=True)\n",
        "    pj = cp.sum(glcm_prob, axis=0, keepdims=True)\n",
        "    mu_i = cp.sum(i * pi)\n",
        "    mu_j = cp.sum(j * pj)\n",
        "    sigma_i = cp.sqrt(cp.sum(((i - mu_i)**2) * pi))\n",
        "    sigma_j = cp.sqrt(cp.sum(((j - mu_j)**2) * pj))\n",
        "\n",
        "    # Avoid division by zero.\n",
        "    if sigma_i == 0 or sigma_j == 0:\n",
        "        correlation = cp.array(0.0)\n",
        "    else:\n",
        "        correlation = cp.sum(((i - mu_i) * (j - mu_j) * glcm_prob) / (sigma_i * sigma_j))\n",
        "\n",
        "    return {\n",
        "        'contrast': float(contrast.get()),\n",
        "        'energy': float(energy.get()),\n",
        "        'homogeneity': float(homogeneity.get()),\n",
        "        'correlation': float(correlation.get())\n",
        "    }\n",
        "\n",
        "def compute_multidirectional_glcm_features(image, levels=8, offsets=None):\n",
        "    \"\"\"\n",
        "    Compute and concatenate GLCM features for multiple directions.\n",
        "\n",
        "    Parameters:\n",
        "      image   : 2D numpy array (quantized grayscale image)\n",
        "      levels  : Number of gray levels (default is 8)\n",
        "      offsets : Dictionary with direction names as keys and offset tuples as values.\n",
        "                Defaults to four directions: 0°, 45°, 90°, and 135°.\n",
        "\n",
        "    Returns:\n",
        "      Dictionary of concatenated features with keys indicating the direction.\n",
        "    \"\"\"\n",
        "    if offsets is None:\n",
        "        offsets = {\n",
        "            '0':   (0, 1),   # 0°\n",
        "            '45':  (-1, 1),  # 45°\n",
        "            '90':  (-1, 0),  # 90°\n",
        "            '135': (-1, -1)  # 135°\n",
        "        }\n",
        "\n",
        "    features = {}\n",
        "    # Loop over each direction, compute features, and store with directional keys.\n",
        "    for direction, off in offsets.items():\n",
        "        feat = compute_glcm_features_for_offset(image, levels=levels, offset=off)\n",
        "        for key, value in feat.items():\n",
        "            features[f\"{key}_{direction}\"] = value\n",
        "    return features\n",
        "\n",
        "# Process each image, compute multi-directional GLCM features, and collect features with label.\n",
        "features_list = []\n",
        "for file, label in tqdm(image_files, desc=\"Processing images\"):\n",
        "    # Read the image in grayscale\n",
        "    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        continue  # Skip images that fail to load\n",
        "\n",
        "    # Quantize the image to reduce intensity levels (default is 8 levels)\n",
        "    img_q = quantize_image(img, levels=8)\n",
        "\n",
        "    # Compute concatenated multi-directional GLCM features.\n",
        "    feats = compute_multidirectional_glcm_features(img_q, levels=8)\n",
        "    feats['filename'] = file\n",
        "    feats['label'] = label  # Add the folder/label information\n",
        "    features_list.append(feats)\n",
        "\n",
        "# Convert the list of feature dictionaries into a Pandas DataFrame.\n",
        "df_features = pd.DataFrame(features_list)\n",
        "print(df_features.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPU_GLRM_Calc:-"
      ],
      "metadata": {
        "id": "l07q2clyXC3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import cupy as cp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ---------------------------\n",
        "# GPU-accelerated helper functions\n",
        "# ---------------------------\n",
        "\n",
        "def quantize_image_gpu(d_img, levels=64):\n",
        "    \"\"\"Quantize image (a CuPy array) to specified gray levels on the GPU.\"\"\"\n",
        "    max_val = cp.max(d_img)\n",
        "    quantized = cp.floor_divide(d_img, (max_val + 1) // levels)\n",
        "    return quantized.astype(cp.uint8)\n",
        "\n",
        "# CUDA kernel for horizontal (0°) run-length computation\n",
        "horizontal_kernel_code = r'''\n",
        "extern \"C\" __global__\n",
        "void compute_glrlm_horizontal(const unsigned char* img, int height, int width, int glrlm_width, unsigned int* glrlm) {\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (row < height) {\n",
        "        int offset = row * width;\n",
        "        unsigned char current = img[offset];\n",
        "        int run_length = 1;\n",
        "        for (int j = 1; j < width; j++) {\n",
        "            unsigned char pixel = img[offset + j];\n",
        "            if (pixel == current) {\n",
        "                run_length++;\n",
        "            } else {\n",
        "                int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "                atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "                current = pixel;\n",
        "                run_length = 1;\n",
        "            }\n",
        "        }\n",
        "        int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "        atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# CUDA kernel for vertical (90°) run-length computation\n",
        "vertical_kernel_code = r'''\n",
        "extern \"C\" __global__\n",
        "void compute_glrlm_vertical(const unsigned char* img, int height, int width, int glrlm_width, unsigned int* glrlm) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (col < width) {\n",
        "        unsigned char current = img[col]; // first row at this column\n",
        "        int run_length = 1;\n",
        "        for (int i = 1; i < height; i++) {\n",
        "            unsigned char pixel = img[i * width + col];\n",
        "            if (pixel == current) {\n",
        "                run_length++;\n",
        "            } else {\n",
        "                int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "                atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "                current = pixel;\n",
        "                run_length = 1;\n",
        "            }\n",
        "        }\n",
        "        int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "        atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# CUDA kernel for 45° (diagonal upward-right) computation\n",
        "diagonal45_kernel_code = r'''\n",
        "extern \"C\" __global__\n",
        "void compute_glrlm_45(const unsigned char* img, int height, int width, int glrlm_width, unsigned int* glrlm) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total = height * width;\n",
        "    if (idx < total) {\n",
        "        int i = idx / width;\n",
        "        int j = idx % width;\n",
        "        unsigned char current = img[i * width + j];\n",
        "        int run_length = 1;\n",
        "        int x = i - 1;\n",
        "        int y = j + 1;\n",
        "        while (x >= 0 && y < width) {\n",
        "            if (img[x * width + y] == current) {\n",
        "                run_length++;\n",
        "                x--;\n",
        "                y++;\n",
        "            } else {\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "        int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "        atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# CUDA kernel for 135° (diagonal downward-right) computation\n",
        "diagonal135_kernel_code = r'''\n",
        "extern \"C\" __global__\n",
        "void compute_glrlm_135(const unsigned char* img, int height, int width, int glrlm_width, unsigned int* glrlm) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total = height * width;\n",
        "    if (idx < total) {\n",
        "        int i = idx / width;\n",
        "        int j = idx % width;\n",
        "        unsigned char current = img[i * width + j];\n",
        "        int run_length = 1;\n",
        "        int x = i + 1;\n",
        "        int y = j + 1;\n",
        "        while (x < height && y < width) {\n",
        "            if (img[x * width + y] == current) {\n",
        "                run_length++;\n",
        "                x++;\n",
        "                y++;\n",
        "            } else {\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "        int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "        atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# Compile the kernels\n",
        "horizontal_kernel = cp.RawKernel(horizontal_kernel_code, 'compute_glrlm_horizontal')\n",
        "vertical_kernel = cp.RawKernel(vertical_kernel_code, 'compute_glrlm_vertical')\n",
        "diagonal45_kernel = cp.RawKernel(diagonal45_kernel_code, 'compute_glrlm_45')\n",
        "diagonal135_kernel = cp.RawKernel(diagonal135_kernel_code, 'compute_glrlm_135')\n",
        "\n",
        "def compute_glrlm_gpu(d_img, direction):\n",
        "    \"\"\"\n",
        "    Compute the GLRLM on the GPU for the given direction.\n",
        "    d_img: quantized image (CuPy array, uint8) with shape (height, width)\n",
        "    direction: one of {0, 45, 90, 135}\n",
        "    Returns a CuPy array representing the GLRLM.\n",
        "    \"\"\"\n",
        "    height, width = d_img.shape\n",
        "    levels = int(cp.max(d_img).get()) + 1\n",
        "    max_run_length = max(height, width)  # maximum possible run length\n",
        "    d_glrlm = cp.zeros((levels, max_run_length), dtype=cp.uint32)\n",
        "\n",
        "    if direction == 0:  # Horizontal\n",
        "        threads = 32\n",
        "        blocks = (height + threads - 1) // threads\n",
        "        horizontal_kernel((blocks,), (threads,), (d_img, height, width, max_run_length, d_glrlm))\n",
        "    elif direction == 90:  # Vertical\n",
        "        threads = 32\n",
        "        blocks = (width + threads - 1) // threads\n",
        "        vertical_kernel((blocks,), (threads,), (d_img, height, width, max_run_length, d_glrlm))\n",
        "    elif direction == 45:  # Diagonal (45°)\n",
        "        total = height * width\n",
        "        threads = 256\n",
        "        blocks = (total + threads - 1) // threads\n",
        "        diagonal45_kernel((blocks,), (threads,), (d_img, height, width, max_run_length, d_glrlm))\n",
        "    elif direction == 135:  # Diagonal (135°)\n",
        "        total = height * width\n",
        "        threads = 256\n",
        "        blocks = (total + threads - 1) // threads\n",
        "        diagonal135_kernel((blocks,), (threads,), (d_img, height, width, max_run_length, d_glrlm))\n",
        "    else:\n",
        "        raise ValueError(\"Direction must be one of {0, 45, 90, 135}\")\n",
        "\n",
        "    cp.cuda.Stream.null.synchronize()\n",
        "    return d_glrlm\n",
        "\n",
        "def extract_glrlm_features_gpu(d_glrlm):\n",
        "    \"\"\"Extract GLRLM features on the GPU and return them as a list of floats.\"\"\"\n",
        "    total_runs = cp.sum(d_glrlm)\n",
        "    run_indices = cp.arange(1, d_glrlm.shape[1] + 1, dtype=cp.float32)\n",
        "    sre = cp.sum(d_glrlm / (run_indices**2)[None, :]) / total_runs\n",
        "    lre = cp.sum(d_glrlm * (run_indices**2)[None, :]) / total_runs\n",
        "    gln = cp.sum(cp.sum(d_glrlm, axis=1)**2) / (total_runs**2)\n",
        "    rln = cp.sum(cp.sum(d_glrlm, axis=0)**2) / (total_runs**2)\n",
        "    return [float(sre.get()), float(lre.get()), float(gln.get()), float(rln.get())]\n",
        "\n",
        "def extract_features_from_image_gpu(img_path):\n",
        "    \"\"\"\n",
        "    Read an image from disk, transfer it to the GPU, quantize it, compute the GLRLM\n",
        "    for each direction, extract features from each, and concatenate all features.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    d_img = cp.asarray(img)\n",
        "    # Quantize image on GPU (using 16 levels for feature extraction)\n",
        "    d_img = quantize_image_gpu(d_img, levels=16)\n",
        "\n",
        "    all_features = []\n",
        "    for direction in [0, 45, 90, 135]:\n",
        "        d_glrlm = compute_glrlm_gpu(d_img, direction)\n",
        "        features = extract_glrlm_features_gpu(d_glrlm)\n",
        "        all_features += features  # concatenate features from each direction\n",
        "    return all_features\n",
        "\n",
        "# ---------------------\n",
        "# Dataset Preparation\n",
        "# ---------------------\n",
        "\n",
        "# Set your dataset path and categories accordingly\n",
        "dataset_path = \"garbage_classification/garbage_classification\"  # Change to your dataset location\n",
        "# Make sure to define CATEGORIES as a list of class names\n",
        "CATEGORIES = ['battery', 'biological', 'brown-glass', 'cardboard', 'clothes', 'green-glass', 'metal', 'paper', 'plastic', 'shoes', 'trash', 'white-glass']\n",
        "\n",
        "features_list = []\n",
        "labels_list = []\n",
        "\n",
        "print(f\"Dataset path: {dataset_path}\")\n",
        "if not os.path.exists(dataset_path):\n",
        "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}. Please check the path.\")\n",
        "\n",
        "print(\"Subdirectories:\", os.listdir(dataset_path))\n",
        "\n",
        "# Process each class\n",
        "for class_idx, class_name in enumerate(CATEGORIES):\n",
        "    class_dir = os.path.join(dataset_path, class_name)\n",
        "    if not os.path.exists(class_dir):\n",
        "        print(f\"Warning: Class directory '{class_dir}' not found. Skipping this class.\")\n",
        "        continue\n",
        "    for img_file in os.listdir(class_dir):\n",
        "        img_path = os.path.join(class_dir, img_file)\n",
        "        if not os.path.isfile(img_path):\n",
        "            print(f\"Warning: File '{img_path}' not found. Skipping this file.\")\n",
        "            continue\n",
        "        features_list.append(extract_features_from_image_gpu(img_path))\n",
        "        labels_list.append(class_idx)\n",
        "\n",
        "# Convert features and labels to numpy arrays (on CPU)\n",
        "X = np.array(features_list)\n",
        "y = np.array(labels_list)\n",
        "\n",
        "# ---------------------\n",
        "# Prepare data for Neural Network Training\n",
        "# ---------------------\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_cat = to_categorical(y, num_classes=len(CATEGORIES))\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n",
        "\n",
        "# ---------------------\n",
        "# Build a Multilayer Neural Network (MLP)\n",
        "# ---------------------\n",
        "\n",
        "input_dim = X_train.shape[1]  # should be 16 features (4 features x 4 directions)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_dim=input_dim),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(len(CATEGORIES), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ---------------------\n",
        "# Train the Neural Network\n",
        "# ---------------------\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=16,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nTest Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Display detailed classification report\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=CATEGORIES))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# ---------------------\n",
        "# Example Prediction Function\n",
        "# ---------------------\n",
        "\n",
        "def predict_texture(img_path):\n",
        "    feat = extract_features_from_image_gpu(img_path)\n",
        "    feat = np.array(feat).reshape(1, -1)\n",
        "    pred_probs = model.predict(feat)\n",
        "    return CATEGORIES[np.argmax(pred_probs)]\n",
        "\n",
        "# Example usage:\n",
        "# print(predict_texture(\"path/to/your/image.jpg\"))\n"
      ],
      "metadata": {
        "id": "zVfy7KVeXDOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Singleimg_GPU_GLRM_Calc:-"
      ],
      "metadata": {
        "id": "QBTlPOJfykPp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PhV_Y8j8yk9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import cupy as cp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ---------------------------\n",
        "# GPU-accelerated helper functions\n",
        "# ---------------------------\n",
        "\n",
        "def quantize_image_gpu(d_img, levels=64):\n",
        "    \"\"\"Quantize image (a CuPy array) to specified gray levels on the GPU.\"\"\"\n",
        "    max_val = cp.max(d_img)\n",
        "    quantized = cp.floor_divide(d_img, (max_val + 1) // levels)\n",
        "    return quantized.astype(cp.uint8)\n",
        "\n",
        "# CUDA kernel for horizontal (0°) run-length computation\n",
        "horizontal_kernel_code = r'''\n",
        "extern \"C\" __global__\n",
        "void compute_glrlm_horizontal(const unsigned char* img, int height, int width, int glrlm_width, unsigned int* glrlm) {\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (row < height) {\n",
        "        int offset = row * width;\n",
        "        unsigned char current = img[offset];\n",
        "        int run_length = 1;\n",
        "        for (int j = 1; j < width; j++) {\n",
        "            unsigned char pixel = img[offset + j];\n",
        "            if (pixel == current) {\n",
        "                run_length++;\n",
        "            } else {\n",
        "                int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "                atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "                current = pixel;\n",
        "                run_length = 1;\n",
        "            }\n",
        "        }\n",
        "        int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "        atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# CUDA kernel for vertical (90°) run-length computation\n",
        "vertical_kernel_code = r'''\n",
        "extern \"C\" __global__\n",
        "void compute_glrlm_vertical(const unsigned char* img, int height, int width, int glrlm_width, unsigned int* glrlm) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (col < width) {\n",
        "        unsigned char current = img[col]; // first row at this column\n",
        "        int run_length = 1;\n",
        "        for (int i = 1; i < height; i++) {\n",
        "            unsigned char pixel = img[i * width + col];\n",
        "            if (pixel == current) {\n",
        "                run_length++;\n",
        "            } else {\n",
        "                int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "                atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "                current = pixel;\n",
        "                run_length = 1;\n",
        "            }\n",
        "        }\n",
        "        int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "        atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# CUDA kernel for 45° (diagonal upward-right) computation\n",
        "diagonal45_kernel_code = r'''\n",
        "extern \"C\" __global__\n",
        "void compute_glrlm_45(const unsigned char* img, int height, int width, int glrlm_width, unsigned int* glrlm) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total = height * width;\n",
        "    if (idx < total) {\n",
        "        int i = idx / width;\n",
        "        int j = idx % width;\n",
        "        unsigned char current = img[i * width + j];\n",
        "        int run_length = 1;\n",
        "        int x = i - 1;\n",
        "        int y = j + 1;\n",
        "        while (x >= 0 && y < width) {\n",
        "            if (img[x * width + y] == current) {\n",
        "                run_length++;\n",
        "                x--;\n",
        "                y++;\n",
        "            } else {\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "        int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "        atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# CUDA kernel for 135° (diagonal downward-right) computation\n",
        "diagonal135_kernel_code = r'''\n",
        "extern \"C\" __global__\n",
        "void compute_glrlm_135(const unsigned char* img, int height, int width, int glrlm_width, unsigned int* glrlm) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total = height * width;\n",
        "    if (idx < total) {\n",
        "        int i = idx / width;\n",
        "        int j = idx % width;\n",
        "        unsigned char current = img[i * width + j];\n",
        "        int run_length = 1;\n",
        "        int x = i + 1;\n",
        "        int y = j + 1;\n",
        "        while (x < height && y < width) {\n",
        "            if (img[x * width + y] == current) {\n",
        "                run_length++;\n",
        "                x++;\n",
        "                y++;\n",
        "            } else {\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "        int capped_run = run_length < glrlm_width ? run_length : glrlm_width - 1;\n",
        "        atomicAdd(&glrlm[current * glrlm_width + capped_run], 1);\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# Compile the kernels\n",
        "horizontal_kernel = cp.RawKernel(horizontal_kernel_code, 'compute_glrlm_horizontal')\n",
        "vertical_kernel = cp.RawKernel(vertical_kernel_code, 'compute_glrlm_vertical')\n",
        "diagonal45_kernel = cp.RawKernel(diagonal45_kernel_code, 'compute_glrlm_45')\n",
        "diagonal135_kernel = cp.RawKernel(diagonal135_kernel_code, 'compute_glrlm_135')\n",
        "\n",
        "def compute_glrlm_gpu(d_img, direction):\n",
        "    \"\"\"\n",
        "    Compute the GLRLM on the GPU for the given direction.\n",
        "    d_img: quantized image (CuPy array, uint8) with shape (height, width)\n",
        "    direction: one of {0, 45, 90, 135}\n",
        "    Returns a CuPy array representing the GLRLM.\n",
        "    \"\"\"\n",
        "    height, width = d_img.shape\n",
        "    levels = int(cp.max(d_img).get()) + 1\n",
        "    max_run_length = max(height, width)\n",
        "    d_glrlm = cp.zeros((levels, max_run_length), dtype=cp.uint32)\n",
        "\n",
        "    if direction == 0:\n",
        "        threads = 32\n",
        "        blocks = (height + threads - 1) // threads\n",
        "        horizontal_kernel((blocks,), (threads,), (d_img, height, width, max_run_length, d_glrlm))\n",
        "    elif direction == 90:\n",
        "        threads = 32\n",
        "        blocks = (width + threads - 1) // threads\n",
        "        vertical_kernel((blocks,), (threads,), (d_img, height, width, max_run_length, d_glrlm))\n",
        "    elif direction == 45:\n",
        "        total = height * width\n",
        "        threads = 256\n",
        "        blocks = (total + threads - 1) // threads\n",
        "        diagonal45_kernel((blocks,), (threads,), (d_img, height, width, max_run_length, d_glrlm))\n",
        "    elif direction == 135:\n",
        "        total = height * width\n",
        "        threads = 256\n",
        "        blocks = (total + threads - 1) // threads\n",
        "        diagonal135_kernel((blocks,), (threads,), (d_img, height, width, max_run_length, d_glrlm))\n",
        "    else:\n",
        "        raise ValueError(\"Direction must be one of {0, 45, 90, 135}\")\n",
        "\n",
        "    cp.cuda.Stream.null.synchronize()\n",
        "    return d_glrlm\n",
        "\n",
        "def extract_glrlm_features_gpu(d_glrlm):\n",
        "    \"\"\"Extract GLRLM features on the GPU and return them as a list of floats.\"\"\"\n",
        "    total_runs = cp.sum(d_glrlm)\n",
        "    run_indices = cp.arange(1, d_glrlm.shape[1] + 1, dtype=cp.float32)\n",
        "    sre = cp.sum(d_glrlm / (run_indices**2)[None, :]) / total_runs\n",
        "    lre = cp.sum(d_glrlm * (run_indices**2)[None, :]) / total_runs\n",
        "    gln = cp.sum(cp.sum(d_glrlm, axis=1)**2) / (total_runs**2)\n",
        "    rln = cp.sum(cp.sum(d_glrlm, axis=0)**2) / (total_runs**2)\n",
        "    return [float(sre.get()), float(lre.get()), float(gln.get()), float(rln.get())]\n",
        "\n",
        "def extract_features_from_image_gpu(img_path):\n",
        "    \"\"\"\n",
        "    Read a single image from disk, transfer it to the GPU, quantize it, compute the GLRLM\n",
        "    for each direction, extract features from each, and concatenate all features.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    d_img = cp.asarray(img)\n",
        "    d_img = quantize_image_gpu(d_img, levels=16)\n",
        "\n",
        "    all_features = []\n",
        "    for direction in [0, 45, 90, 135]:\n",
        "        d_glrlm = compute_glrlm_gpu(d_img, direction)\n",
        "        features = extract_glrlm_features_gpu(d_glrlm)\n",
        "        all_features += features\n",
        "    return all_features\n"
      ],
      "metadata": {
        "id": "-CTZzc8gyoTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lipEcNjqzBPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Singleimg_GPU_GLCM_Calc:-"
      ],
      "metadata": {
        "id": "1SC2omEGzC0N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vsx1vu5uzIRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Singleimg_non_GPU_CM"
      ],
      "metadata": {
        "id": "HCqH6VrfZa3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "\n",
        "def quantize_image(image: np.ndarray, levels: int = 8) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Quantize a grayscale image into a fixed number of gray levels.\n",
        "\n",
        "    Parameters:\n",
        "      image  : 2D numpy array (uint8 grayscale image)\n",
        "      levels : Number of gray levels to reduce to (default 8)\n",
        "\n",
        "    Returns:\n",
        "      Quantized image as uint8 array with values in [0, levels-1].\n",
        "    \"\"\"\n",
        "    factor = 256 // levels\n",
        "    return (image // factor).astype(np.uint8)\n",
        "\n",
        "\n",
        "def compute_glcm_matrix(\n",
        "    gray: np.ndarray,\n",
        "    levels: int = 8,\n",
        "    dx: int = 1,\n",
        "    dy: int = 0\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute the Gray-Level Co-occurrence Matrix (GLCM) for a single offset.\n",
        "\n",
        "    Parameters:\n",
        "      gray   : 2D numpy array (quantized grayscale image)\n",
        "      levels : Number of gray levels (default 8)\n",
        "      dx, dy : Offsets defining spatial relationship\n",
        "\n",
        "    Returns:\n",
        "      Normalized GLCM as a 2D numpy array of shape (levels, levels).\n",
        "    \"\"\"\n",
        "    rows, cols = gray.shape\n",
        "    glcm = np.zeros((levels, levels), dtype=np.uint64)\n",
        "\n",
        "    # Define valid index ranges based on offset\n",
        "    i_start, i_end = (-dy, rows) if dy < 0 else (0, rows - dy)\n",
        "    j_start, j_end = (-dx, cols) if dx < 0 else (0, cols - dx)\n",
        "\n",
        "    # Accumulate co-occurrences\n",
        "    for i in range(i_start, i_end):\n",
        "        for j in range(j_start, j_end):\n",
        "            r = gray[i, j]\n",
        "            c = gray[i + dy, j + dx]\n",
        "            glcm[r, c] += 1\n",
        "\n",
        "    # Normalize\n",
        "    total = glcm.sum()\n",
        "    return glcm.astype(np.float64) / total if total > 0 else glcm.astype(np.float64)\n",
        "\n",
        "\n",
        "def extract_glcm_features(glcm: np.ndarray) -> dict:\n",
        "    \"\"\"\n",
        "    Compute texture features from a normalized GLCM.\n",
        "\n",
        "    Features:\n",
        "      - contrast\n",
        "      - energy\n",
        "      - homogeneity\n",
        "      - correlation\n",
        "\n",
        "    Returns:\n",
        "      Dict of feature names to values.\n",
        "    \"\"\"\n",
        "    levels = glcm.shape[0]\n",
        "    i = np.arange(levels).reshape(-1, 1)\n",
        "    j = np.arange(levels).reshape(1, -1)\n",
        "\n",
        "    # Contrast\n",
        "    contrast = np.sum((i - j)**2 * glcm)\n",
        "    # Energy (Angular Second Moment)\n",
        "    energy = np.sum(glcm**2)\n",
        "    # Homogeneity\n",
        "    homogeneity = np.sum(glcm / (1 + np.abs(i - j)))\n",
        "    # Correlation\n",
        "    pi = glcm.sum(axis=1, keepdims=True)\n",
        "    pj = glcm.sum(axis=0, keepdims=True)\n",
        "    mu_i = np.sum(i * pi)\n",
        "    mu_j = np.sum(j * pj)\n",
        "    sigma_i = np.sqrt(np.sum(((i - mu_i)**2) * pi))\n",
        "    sigma_j = np.sqrt(np.sum(((j - mu_j)**2) * pj))\n",
        "\n",
        "    if sigma_i > 0 and sigma_j > 0:\n",
        "        correlation = np.sum((i - mu_i) * (j - mu_j) * glcm) / (sigma_i * sigma_j)\n",
        "    else:\n",
        "        correlation = 0.0\n",
        "\n",
        "    return {\n",
        "        'contrast': float(contrast),\n",
        "        'energy': float(energy),\n",
        "        'homogeneity': float(homogeneity),\n",
        "        'correlation': float(correlation)\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_multidirectional_glcm_features(\n",
        "    image: np.ndarray,\n",
        "    levels: int = 8,\n",
        "    offsets: dict = None\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Compute GLCM features for multiple directions.\n",
        "\n",
        "    Parameters:\n",
        "      image   : 2D numpy array (quantized grayscale image)\n",
        "      levels  : Number of gray levels\n",
        "      offsets : Dict mapping direction names to (dy, dx) tuples\n",
        "                Defaults to {'0':(0,1),'45':(-1,1),'90':(-1,0),'135':(-1,-1)}\n",
        "\n",
        "    Returns:\n",
        "      Dict of feature_<direction> entries for each metric and direction.\n",
        "    \"\"\"\n",
        "    if offsets is None:\n",
        "        offsets = {\n",
        "            '0°':   (0, 1),\n",
        "            '45°':  (-1, 1),\n",
        "            '90°':  (-1, 0),\n",
        "            '135°': (-1, -1)\n",
        "        }\n",
        "    features = {}\n",
        "    for angle, (dy, dx) in offsets.items():\n",
        "        glcm = compute_glcm_matrix(image, levels, dx=dx, dy=dy)\n",
        "        feats = extract_glcm_features(glcm)\n",
        "        for name, val in feats.items():\n",
        "            features[f\"{name}_{angle}\"] = val\n",
        "    return features\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='Compute GLCM texture features for a single image.'\n",
        "    )\n",
        "    parser.add_argument('image_path', help='Path to the grayscale image file')\n",
        "    parser.add_argument(\n",
        "        '--levels', type=int, default=8,\n",
        "        help='Number of gray levels for quantization (default: 8)'\n",
        "    )\n",
        "    return parser.parse_args()\n",
        "\n"
      ],
      "metadata": {
        "id": "7yQR7mm3ZYql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "image_path = 'battery124.jpg'\n",
        "levels = 8\n",
        "# args = parse_args()\n",
        "\n",
        "# Load image in grayscale\n",
        "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "if img is None:\n",
        "    raise FileNotFoundError(f\"Could not open image at {image_path}\")\n",
        "\n",
        "# Quantize image\n",
        "img_q = quantize_image(img, levels)\n",
        "\n",
        "# Compute features\n",
        "features = compute_multidirectional_glcm_features(img_q, levels)\n",
        "\n",
        "# Print features\n",
        "print(\"GLCM texture features:\")\n",
        "for k, v in features.items():\n",
        "    print(f\"{k}: {v:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HgPGWHEZZVC",
        "outputId": "7145d40d-030f-453c-ca27-71df4676df3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLCM texture features:\n",
            "contrast_0°: 0.522646\n",
            "energy_0°: 0.238250\n",
            "homogeneity_0°: 0.933635\n",
            "correlation_0°: 0.971874\n",
            "contrast_45°: 1.034147\n",
            "energy_45°: 0.217632\n",
            "homogeneity_45°: 0.889660\n",
            "correlation_45°: 0.944247\n",
            "contrast_90°: 0.713725\n",
            "energy_90°: 0.227567\n",
            "homogeneity_90°: 0.911987\n",
            "correlation_90°: 0.961561\n",
            "contrast_135°: 1.041624\n",
            "energy_135°: 0.217717\n",
            "homogeneity_135°: 0.891046\n",
            "correlation_135°: 0.943844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr=[i for i in features.values()]\n",
        "arr = np.array(arr)\n",
        "arr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t9-zCaVZZSw",
        "outputId": "66608be5-48d3-4e2f-8f11-1ce3dbb0447b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}